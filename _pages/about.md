---
permalink: /
title: "About Me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Gen Li is a third-year Ph.D. student at Clemson University, under the supervision of Prof. [Xiaolong Ma](https://xiaolongma2016.com/) and co-advised by Prof. [Linlke Guo](https://cecas.clemson.edu/~linkeg/index.html). His primary research focuses on efficient Machine Learning, algorithm-hardware co-design for mobile devices, and fairness and robustness in broad AI applications.

<style>
  .news-container {
    width: 100%;
    max-width: 1200px;
    height: 300px;                 /* 保留固定高度 */
    padding: 16px;                 /* 加大内边距，显得更舒适 */
    overflow-y: auto;              /* 保留上下滑动 */
    background-color: #f5f5f7;     /* 高级感浅灰 */
    border: 1px solid #e0e0e0;     /* 更细更浅的边框 */
    border-radius: 8px;            /* 圆角更明显 */
    box-shadow: 0 4px 8px rgba(0,0,0,0.05);  /* 轻微阴影增添层次 */
    margin-bottom: 30px;
  }
  .news-container .news-title {
    font-family: Arial, sans-serif;
    font-size: 1.25rem;
    color: #333;
    margin: 0 0 12px;
    font-weight: bold;
  }
  .news-container .news-item {
    font-family: Arial, sans-serif;
    font-size: 0.95rem;
    color: #444;
    margin: 8px 0;
    padding-left: 12px;
    position: relative;
  }
  .news-container .news-item::before {
    content: "•";
    position: absolute;
    left: 0;
    top: 0.15em;
    font-size: 1rem;
    color: #999;
  }
</style>

<div class="news-container">
  <div class="news-title">Latest News</div>
  <p class="news-item">06/2025 — Two papers accepted at <strong>ICCV 2025</strong>.</p>
  <p class="news-item">09/2024 — Paper accepted at <strong>NeurIPS 2024</strong>.</p>
  <p class="news-item">09/2024 — Paper accepted at <strong>S&P 2025</strong>.</p>
  <p class="news-item">07/2024 — Paper accepted at <strong>ECCV 2024</strong>.</p>
  <p class="news-item">05/2024 — Two papers accepted at <strong>ICML 2024</strong>.</p>
  <p class="news-item">01/2024 — Paper accepted at <strong>ICLR 2024</strong>.</p>
  <p class="news-item">09/2023 — Paper accepted at <strong>NeurIPS 2023</strong>.</p>
  <p class="news-item">02/2023 — “Spotlight” paper at ICLR SNN Workshop.</p>
  <p class="news-item">02/2023 — “Highlight” paper (top 2.5%) at <strong>CVPR 2023</strong>.</p>
</div>



Selected Publications
======
<div style="font-family: Arial, sans-serif;">
  <style>
    .publication-card {
      padding: 15px;
      margin-bottom: 10px;
      border: 2px solid #dfdfdf;  /* Very light gray border */
      border-radius: 5px;
      transition: box-shadow 0.3s ease, border 0.3s ease;
    }
    .publication-card:hover {
      box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
      border-color: #d0d0d0;  /* Slightly darker gray color on hover */
    }
    .pdf-logo {
      position: absolute;
      bottom: 10px; /* Adjust as needed */
      right: 10px; /* Adjust as needed */
      width: 24px; /* Set the size of the PDF icon */
      height: 24px;
    }
    .pdf-logo img {
      width: 100%; /* Ensure the image fills the anchor */
      height: 100%;
      display: block;
    }
  </style>

  <!-- First Paper -->
  
  <div class="publication-card">
    <h3 style="margin: 5px 0;">Sculpting Memory: Multi-Concept Forgetting in Diffusion Models via Dynamic Mask and Concept-Aware Optimization</h3>
    <p style="margin: 5px 0; color: #4fb2d9;"><i>Gen Li, Yang Xiao, Jie Ji, Kaiyuan Deng, Bo Hui, Linke Guo, Xiaolong Ma</i></p>
    <p style="margin: 5px 0;"><span style="background-color: #f2dede; padding: 2px 5px; border-radius: 3px;">ICCV '25</span> &middot; Acceptance rate: 24% &middot; <a href="https://arxiv.org/abs/2504.09039" 
          target="_blank" 
          rel="noopener noreferrer" 
          style="text-decoration: none; color: #007BFF;">Paper Link</a>
    </p>  
 </div>
  
  <div class="publication-card">
    <h3 style="margin: 5px 0;">Adversarial Robust ViT-based Automatic Modulation Recognition in Practical Deep Learning-based Wireless Systems</h3>
    <p style="margin: 5px 0; color: #4fb2d9;"><i>Gen Li, Chun-Chih Lin, Xiaonan Zhang, Xiaolong Ma, Linke Guo</i></p>
    <p style="margin: 5px 0;"><span style="background-color: #f2dede; padding: 2px 5px; border-radius: 3px;">S&P '25</span> &middot; Acceptance rate: 14.3% &middot; <a href="https://www.computer.org/csdl/proceedings-article/sp/2025/223600a030/21B7Qkjltcs" 
          target="_blank" 
          rel="noopener noreferrer" 
          style="text-decoration: none; color: #007BFF;">Paper Link</a>
    </p>  
 </div>

  <div class="publication-card">
    <h3 style="margin: 5px 0;">A Single-Step, Sharpness-Aware Minimization is All You Need to Achieve Efficient and Accurate Sparse Training</h3>
    <p style="margin: 5px 0; color: #4fb2d9;"><i>Jie Ji, Gen Li, Jingjing Fu, Fatemeh Afghah, Linke Guo, Xiaoyong Yuan, Xiaolong Ma</i></p>
    <p style="margin: 5px 0;"><span style="background-color: #f2dede; padding: 2px 5px; border-radius: 3px;">NeurIPS '24</span> &middot; Acceptance rate: 25.8% &middot; <a href="https://openreview.net/forum?id=MJgMMqMDu4" 
          target="_blank" 
          rel="noopener noreferrer" 
          style="text-decoration: none; color: #007BFF;">Paper Link</a>
    </p>  
  </div>
  
  
  <div class="publication-card">
    <h3 style="margin: 5px 0;">Data Overfitting for On-Device Super-Resolution with Dynamic Algorithm and Compiler Co-Design</h3>
    <p style="margin: 5px 0; color: #4fb2d9;"><i>Gen Li, Zhihao Shu, Jie Ji, Minghai Qin, Fatemeh Afghah, Wei Niu, Xiaolong Ma</i></p>
    <p style="margin: 5px 0;"><span style="background-color: #f2dede; padding: 2px 5px; border-radius: 3px;">ECCV '24</span> &middot; Acceptance rate: 27.9% &middot; <a href="https://arxiv.org/abs/2407.02813" 
          target="_blank" 
          rel="noopener noreferrer" 
          style="text-decoration: none; color: #007BFF;">Paper Link</a>
    </p>  
  </div>
  
  <div class="publication-card">
    <h3 style="margin: 5px 0;">Advancing Dynamic Sparse Training by Exploring Optimization Opportunities</h3>
    <p style="margin: 5px 0; color: #4fb2d9;"><i>Jie Ji*, Gen Li*, Lu Yin, Minghai Qin, Geng Yuan, Linke Guo, Shiwei Liu, Xiaolong Ma</i></p>
    <p style="margin: 5px 0;"><span style="background-color: #f2dede; padding: 2px 5px; border-radius: 3px;">ICML '24</span> &middot; Acceptance rate: 27.5% &middot; <a href="https://openreview.net/forum?id=szRHR9XGrY" 
          target="_blank" 
          rel="noopener noreferrer" 
          style="text-decoration: none; color: #007BFF;">Paper Link</a>
    </p>  
  </div>

  
  <div class="publication-card">
    <h3 style="margin: 5px 0;">Outlier weighed layerwise sparsity (owl): A missing secret sauce for pruning llms to high sparsity</h3>
    <p style="margin: 5px 0; color: #4fb2d9;"><i>Lu Yin, You Wu, Zhenyu Zhang, Cheng-Yu Hsieh, Yaqing Wang, Yiling Jia, Gen Li, Ajay Jaiswal, Mykola Pechenizkiy, Yi Liang, Michael Bendersky, Zhangyang Wang, Shiwei Liu</i></p>
    <p style="margin: 5px 0;"><span style="background-color: #f2dede; padding: 2px 5px; border-radius: 3px;">ICML '24</span> &middot; Acceptance rate: 27.5% &middot; <a href="https://arxiv.org/abs/2310.05175" 
          target="_blank" 
          rel="noopener noreferrer" 
          style="text-decoration: none; color: #007BFF;">Paper Link</a>
    </p>  
  </div>

  <div class="publication-card">
    <h3 style="margin: 5px 0;">NeurRev: Train Better Sparse Neural Network Practically via Neuron Revitalization</h3>
    <p style="margin: 5px 0; color: #4fb2d9;"><i>Gen Li, Lu Yin, Jie Ji, Wei Niu, Minghai Qin, Bin Ren, Linke Guo, Shiwei Liu, Xiaolong Ma</i></p>
    <p style="margin: 5px 0;"><span style="background-color: #f2dede; padding: 2px 5px; border-radius: 3px;">ICLR '24</span>
    &middot; Acceptance rate: 31% &middot; <a href="https://openreview.net/forum?id=60lNoatp7u" 
          target="_blank" 
          rel="noopener noreferrer" 
          style="text-decoration: none; color: #007BFF;">Paper Link</a>
    </p>  
  </div>
  
  <div class="publication-card">
    <h3 style="margin: 5px 0;">Dynamic Sparsity Is Channel-Level Sparsity Learner</h3>
    <p style="margin: 5px 0; color: #4fb2d9;"><i>Lu Yin, Gen Li, Meng Fang, Li Shen, Tianjin Huang, Zhangyang Wang, Vlado Menkovski, Xiaolong Ma, Mykola Pechenizkiy, Shiwei Liu</i></p>
    <p style="margin: 5px 0;"><span style="background-color: #f2dede; padding: 2px 5px; border-radius: 3px;">NeurIPS '23</span> &middot; Acceptance rate: 26.1% &middot; <a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/d6d0e41e0b1ed38c76d13c9e417a8f1f-Paper-Conference.pdf" 
          target="_blank" 
          rel="noopener noreferrer" 
          style="text-decoration: none; color: #007BFF;">Paper Link</a>
    </p>  
  </div>

  <div class="publication-card">
    <h3 style="margin: 5px 0;">Towards High-Quality and Efficient Video Super-Resolution via Spatial-Temporal Data Overfitting</h3>
    <p style="margin: 5px 0; color: #4fb2d9;"><i>Gen Li, Jie Ji, Minghai Qin, Wei Niu, Bin Ren, Fatemeh Afghah, Linke Guo, Xiaolong Ma</i></p>
    <p style="margin: 5px 0;"><span style="background-color: #f2dede; padding: 2px 5px; border-radius: 3px;">CVPR '23</span> &middot; Highlight paper: top 2.5%  &middot; <a href="https://ieeexplore.ieee.org/abstract/document/10203894" 
          target="_blank" 
          rel="noopener noreferrer" 
          style="text-decoration: none; color: #007BFF;">Paper Link</a>
    </p>  
  </div>

</div>
